{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring OLS and WLS using NumPy and matplotlib\n",
    "Author: BjÃ¶rn Dahlgren, 2016-04-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def rnd(shape, positive=True):\n",
    "    if positive:\n",
    "        return np.abs(np.random.normal(size=shape))\n",
    "        #return np.random.random(shape)\n",
    "    else:\n",
    "        return np.random.normal(size=shape)\n",
    "        #return np.random.random(shape) - 0.5\n",
    "true_beta = [np.exp(1), -np.pi]\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(N=20, rel_minerr=1e-2, abs_maxerr=.2, xmin=0, xmax=1):\n",
    "    x = np.linspace(xmin, xmax, N)\n",
    "    err = rnd(x.shape)*(1 - rel_minerr) + rel_minerr\n",
    "    heteroscedastic=0\n",
    "    homoscedastic=1\n",
    "    y = ((true_beta[1] + (abs_maxerr*rnd(x.shape, False)*err)*heteroscedastic)*x + \n",
    "         true_beta[0] + (abs_maxerr*rnd(x.shape, False)*err)*homoscedastic)\n",
    "    return x, y, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y, err = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(*args):\n",
    "    plt.errorbar(x, y, yerr=err, ls='None', marker='.')\n",
    "    for beta in args:\n",
    "        plt.plot(x, beta[0] + x*beta[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plot(true_beta)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(err, '.')\n",
    "plt.subplot(1, 3, 3)\n",
    "_ = plt.errorbar(x/err, (y-true_beta[0])/err, yerr=err, marker='.', ls='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LS(x, y, w=1):  # w == 1 => OLS, w != 1 => WLS\n",
    "    \"\"\" Least squares \n",
    "    \n",
    "    References\n",
    "    -----------\n",
    "    Wikipedia & standard texts on least squares.\n",
    "    A note about R2 in WLS:\n",
    "        Willett, John B., and Judith D. Singer. \"Another cautionary note about R 2:\n",
    "        Its use in weighted least-squares regression analysis.\"\n",
    "        The American Statistician 42.3 (1988): 236-238.\n",
    "    \"\"\"\n",
    "    sqrtw = np.sqrt(w)\n",
    "    y = y * sqrtw\n",
    "    X = np.ones((x.size, 2))\n",
    "    X[:, 1] = x\n",
    "    if hasattr(sqrtw, 'ndim') and sqrtw.ndim == 1:\n",
    "        sqrtw = sqrtw.reshape((sqrtw.size, 1))\n",
    "    X *= sqrtw\n",
    "    \n",
    "    beta = np.linalg.lstsq(X, y)[0]\n",
    "    eps = X.dot(beta) - y\n",
    "    SSR = eps.T.dot(eps)  # sum of squared residuals\n",
    "    vcv = SSR/(x.size - 2)*np.linalg.inv(X.T.dot(X))\n",
    "    TSS = np.sum(np.square(y - np.mean(y)))  # total sum of squares\n",
    "    R2 = 1 - SSR/TSS\n",
    "    return beta, vcv, R2\n",
    "    XtX = X.T.dot(X)\n",
    "    return np.linalg.lstsq(XtX, X.T.dot(y))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(x, beta):\n",
    "    X = np.ones((x.size, 2))\n",
    "    X[:, 1] = x\n",
    "    return X.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta, vcv, R2 = LS(x, y)\n",
    "beta_w, vcv_w, R2_w = LS(x, y, err**-2)\n",
    "plot(true_beta, beta, beta_w)\n",
    "print(beta, np.diag(vcv)**0.5, R2)\n",
    "print(beta_w, np.diag(vcv_w)**0.5, R2_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "ols_model = sm.OLS(y, sm.add_constant(x))\n",
    "wls_model = sm.WLS(y, sm.add_constant(x), weights=err**-2)\n",
    "ols_res = ols_model.fit()\n",
    "wls_res = wls_model.fit()\n",
    "print(ols_res.params, ols_res.bse, ols_res.rsquared)\n",
    "print(wls_res.params, wls_res.bse, wls_res.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling multiple reggresions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_average(obs, s2):\n",
    "    avg, sum_of_w = np.average(obs, axis=0, weights=1/s2, returned=True)\n",
    "    var = np.sum(np.square(obs - avg)/s2, axis=0)/((avg.shape[0] - 1) * sum_of_w)\n",
    "    return avg, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_average_plot(obs, s2, xlbl=r'$\\beta_0$', ylbl=r'$\\beta_1$', ttl=r'$y(x) = \\beta_0 + \\beta_1 \\cdot x$',\n",
    "                         label_cb=None):\n",
    "    plt.errorbar(obs[:, 0], obs[:, 1], marker='s', ls='None', xerr=s2[:, 0]**0.5, yerr=s2[:, 1]**0.5, alpha=.5)\n",
    "    plt.xlabel(xlbl); plt.ylabel(ylbl); plt.title(ttl)\n",
    "    avg, var = weighted_average(obs, s2)\n",
    "    lbl = None if label_cb is None else label_cb(avg, var)\n",
    "    plt.errorbar(avg[0], avg[1], xerr=var[0]**0.5, yerr=var[1]**0.5, marker='o', c='r',\n",
    "                 linewidth=2, markersize=10, label=lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ns = [32, 17, 43, 29, 31, 37]\n",
    "beta = np.empty((len(Ns), 2))\n",
    "s2 = np.empty_like(beta)\n",
    "for idx, N in enumerate(Ns):\n",
    "    x, y, err = get_data()\n",
    "    beta[idx, :], cov, R2 = LS(x, y, err**-2)\n",
    "    s2[idx, :] = np.diag(cov)\n",
    "weighted_average_plot(beta, s2)\n",
    "plt.gca().set_xlim([true_beta[0]-.1, true_beta[0]+.1]), plt.gca().set_ylim([true_beta[1]-.1, true_beta[1]+.1])\n",
    "#plt.legend(numpoints=1)_ = plt.legend(numpoints=1)\n",
    "_ = plt.plot(*true_beta, c='g', marker='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing OLS vs. WLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_N = np.logspace(1, 3, 20000)\n",
    "R2 = np.empty((2, all_N.size))\n",
    "beta = np.empty((2, all_N.size, 2))\n",
    "cov = np.empty((2, all_N.size, 2, 2))\n",
    "for idx_N, N in enumerate(all_N):\n",
    "    x, y, err = get_data(N)\n",
    "    for idx_m, w in enumerate([1, err**-2]):\n",
    "        beta[idx_m, idx_N, :], cov[idx_m, idx_N, :, :], R2[idx_m, idx] = LS(x, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "for idx_beta, true_val in enumerate(true_beta):\n",
    "    for idx_m, lbl in enumerate(['OLS', 'WLS']):\n",
    "        ax = plt.subplot(2, 2, idx_beta+1)\n",
    "        style = dict(c='bg'[idx_m], ls='None', marker='.',)\n",
    "        plt.plot(all_N, np.abs(beta[idx_m, :, idx_beta] - true_val),\n",
    "                     #yerr=cov[idx_m, :, idx_beta, idx_beta]**0.5,\n",
    "                alpha=0.1, **style)\n",
    "        plt.plot(np.nan, np.nan, label=lbl, **style)  # avoid alpha in legend\n",
    "        \n",
    "        ax = plt.subplot(2, 2, idx_beta+3)\n",
    "        plt.plot(all_N, cov[idx_m, :, idx_beta, idx_beta],\n",
    "                     #yerr=cov[idx_m, :, idx_beta, idx_beta]**0.5,\n",
    "                alpha=0.1, **style)\n",
    "        plt.plot(np.nan, np.nan, label=lbl, **style)  # avoid alpha in legend\n",
    "        \n",
    "    ax = plt.subplot(2, 2, idx_beta+1)\n",
    "    ax.set_xscale('log')\n",
    "    ax.legend(numpoints=1, loc='best', frameon=False)\n",
    "    ax.set_xlabel(r'$n_{obs}$', fontsize=16)\n",
    "    ax.set_ylabel(r'$| \\beta_%d - \\hat{\\beta}_%d |$' % (idx_beta, idx_beta), fontsize=16)\n",
    "    \n",
    "    ax = plt.subplot(2, 2, idx_beta+3)\n",
    "    ax.set_xscale('log')\n",
    "    ax.legend(numpoints=1, loc='best', frameon=False)\n",
    "    ax.set_xlabel(r'$n_{obs}$', fontsize=16)\n",
    "    ax.set_ylabel(r'$var(\\hat{\\beta}_%d)$' % idx_beta, fontsize=16)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
